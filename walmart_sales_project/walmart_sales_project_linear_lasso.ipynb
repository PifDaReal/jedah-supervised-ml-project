{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import  OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "...Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import dataset\n",
    "print(\"Loading dataset...\")\n",
    "df = pd.read_csv('Walmart_Store_sales.csv')\n",
    "print(\"...Done.\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'], format='%d-%m-%Y')\n",
    "df['Weekly_Sales'] = df['Weekly_Sales'].round(2)\n",
    "df['year'] = df['Date'].dt.year\n",
    "df['month'] = df['Date'].dt.month\n",
    "df['day'] = df['Date'].dt.day\n",
    "df['day_of_week'] = df['Date'].dt.day_of_week\n",
    "df = df.dropna(subset=['Weekly_Sales'])\n",
    "df = df.sort_values(by=['Store'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.convert_dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 136 entries, 73 to 110\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   Store         136 non-null    Int64         \n",
      " 1   Date          118 non-null    datetime64[ns]\n",
      " 2   Weekly_Sales  136 non-null    Float64       \n",
      " 3   Holiday_Flag  125 non-null    Int64         \n",
      " 4   Temperature   121 non-null    Float64       \n",
      " 5   Fuel_Price    124 non-null    Float64       \n",
      " 6   CPI           125 non-null    Float64       \n",
      " 7   Unemployment  122 non-null    Float64       \n",
      " 8   year          118 non-null    Int64         \n",
      " 9   month         118 non-null    Int64         \n",
      " 10  day           118 non-null    Int64         \n",
      " 11  day_of_week   118 non-null    Int64         \n",
      "dtypes: Float64(5), Int64(6), datetime64[ns](1)\n",
      "memory usage: 15.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Date</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>Holiday_Flag</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-08-27</td>\n",
       "      <td>1449142.92</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>85.22</td>\n",
       "      <td>2.619</td>\n",
       "      <td>211.567306</td>\n",
       "      <td>7.787</td>\n",
       "      <td>2010</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-12</td>\n",
       "      <td>1641957.44</td>\n",
       "      <td>1</td>\n",
       "      <td>38.51</td>\n",
       "      <td>2.548</td>\n",
       "      <td>211.24217</td>\n",
       "      <td>8.106</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-11-18</td>\n",
       "      <td>1539483.7</td>\n",
       "      <td>0</td>\n",
       "      <td>62.25</td>\n",
       "      <td>3.308</td>\n",
       "      <td>218.220509</td>\n",
       "      <td>7.866</td>\n",
       "      <td>2011</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>2012-03-16</td>\n",
       "      <td>1677472.78</td>\n",
       "      <td>0</td>\n",
       "      <td>64.74</td>\n",
       "      <td>3.734</td>\n",
       "      <td>221.211813</td>\n",
       "      <td>7.348</td>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-05-14</td>\n",
       "      <td>1494251.5</td>\n",
       "      <td>0</td>\n",
       "      <td>74.78</td>\n",
       "      <td>2.854</td>\n",
       "      <td>210.337426</td>\n",
       "      <td>7.808</td>\n",
       "      <td>2010</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Store       Date  Weekly_Sales  Holiday_Flag  Temperature  Fuel_Price  \\\n",
       "73      1 2010-08-27    1449142.92          <NA>        85.22       2.619   \n",
       "44      1 2010-02-12    1641957.44             1        38.51       2.548   \n",
       "78      1 2011-11-18     1539483.7             0        62.25       3.308   \n",
       "13      1 2012-03-16    1677472.78             0        64.74       3.734   \n",
       "95      1 2010-05-14     1494251.5             0        74.78       2.854   \n",
       "\n",
       "           CPI  Unemployment  year  month  day  day_of_week  \n",
       "73  211.567306         7.787  2010      8   27            4  \n",
       "44   211.24217         8.106  2010      2   12            4  \n",
       "78  218.220509         7.866  2011     11   18            4  \n",
       "13  221.211813         7.348  2012      3   16            4  \n",
       "95  210.337426         7.808  2010      5   14            4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Date</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>Holiday_Flag</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>90.0</td>\n",
       "      <td>80</td>\n",
       "      <td>90.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.9</td>\n",
       "      <td>2011-05-17 11:06:00</td>\n",
       "      <td>1233864.509</td>\n",
       "      <td>0.075</td>\n",
       "      <td>61.061</td>\n",
       "      <td>3.318444</td>\n",
       "      <td>179.524905</td>\n",
       "      <td>7.389733</td>\n",
       "      <td>2010.8875</td>\n",
       "      <td>6.3625</td>\n",
       "      <td>16.125</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2010-02-05 00:00:00</td>\n",
       "      <td>268929.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.79</td>\n",
       "      <td>2.548</td>\n",
       "      <td>126.128355</td>\n",
       "      <td>5.143</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2010-08-04 06:00:00</td>\n",
       "      <td>561724.0475</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.3425</td>\n",
       "      <td>2.81475</td>\n",
       "      <td>132.602339</td>\n",
       "      <td>6.64225</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.0</td>\n",
       "      <td>2011-05-16 12:00:00</td>\n",
       "      <td>1260826.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.45</td>\n",
       "      <td>3.468</td>\n",
       "      <td>197.166416</td>\n",
       "      <td>7.419</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.75</td>\n",
       "      <td>2012-02-18 18:00:00</td>\n",
       "      <td>1807159.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.7925</td>\n",
       "      <td>3.73775</td>\n",
       "      <td>214.855374</td>\n",
       "      <td>8.099</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>8.25</td>\n",
       "      <td>23.25</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20.0</td>\n",
       "      <td>2012-10-19 00:00:00</td>\n",
       "      <td>2771397.17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>91.65</td>\n",
       "      <td>4.17</td>\n",
       "      <td>226.968844</td>\n",
       "      <td>9.342</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.204475</td>\n",
       "      <td>NaN</td>\n",
       "      <td>664725.013301</td>\n",
       "      <td>0.265053</td>\n",
       "      <td>17.74604</td>\n",
       "      <td>0.484399</td>\n",
       "      <td>39.554303</td>\n",
       "      <td>0.982729</td>\n",
       "      <td>0.826672</td>\n",
       "      <td>3.028321</td>\n",
       "      <td>8.521566</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Store                 Date   Weekly_Sales  Holiday_Flag  \\\n",
       "count      90.0                   80           90.0          80.0   \n",
       "mean        9.9  2011-05-17 11:06:00    1233864.509         0.075   \n",
       "min         1.0  2010-02-05 00:00:00      268929.03           0.0   \n",
       "25%         4.0  2010-08-04 06:00:00    561724.0475           0.0   \n",
       "50%         9.0  2011-05-16 12:00:00      1260826.1           0.0   \n",
       "75%       15.75  2012-02-18 18:00:00     1807159.02           0.0   \n",
       "max        20.0  2012-10-19 00:00:00     2771397.17           1.0   \n",
       "std    6.204475                  NaN  664725.013301      0.265053   \n",
       "\n",
       "       Temperature  Fuel_Price         CPI  Unemployment       year     month  \\\n",
       "count         90.0        90.0        90.0          90.0       80.0      80.0   \n",
       "mean        61.061    3.318444  179.524905      7.389733  2010.8875    6.3625   \n",
       "min          18.79       2.548  126.128355         5.143     2010.0       1.0   \n",
       "25%        45.3425     2.81475  132.602339       6.64225     2010.0       4.0   \n",
       "50%          61.45       3.468  197.166416         7.419     2011.0       6.0   \n",
       "75%        75.7925     3.73775  214.855374         8.099     2012.0      8.25   \n",
       "max          91.65        4.17  226.968844         9.342     2012.0      12.0   \n",
       "std       17.74604    0.484399   39.554303      0.982729   0.826672  3.028321   \n",
       "\n",
       "            day  day_of_week  \n",
       "count      80.0         80.0  \n",
       "mean     16.125          4.0  \n",
       "min         1.0          4.0  \n",
       "25%        10.0          4.0  \n",
       "50%        16.5          4.0  \n",
       "75%       23.25          4.0  \n",
       "max        31.0          4.0  \n",
       "std    8.521566          0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Enlèvement des Outliers\n",
    "remove_outlier=['Temperature','Fuel_Price','CPI','Unemployment']\n",
    "\n",
    "for col in remove_outlier:\n",
    "    mean = df[col].mean()\n",
    "    std= df[col].std()\n",
    "\n",
    "    mask = np.abs((df[col] - mean) <= 3* std) & ((df[col] - mean) >= - 3* std)\n",
    "    df = df[mask]\n",
    "\n",
    "display(df.head())\n",
    "print()\n",
    "display(df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separating labels from features...\n",
      "...Done.\n",
      "73    1449142.92\n",
      "44    1641957.44\n",
      "78     1539483.7\n",
      "13    1677472.78\n",
      "95     1494251.5\n",
      "Name: Weekly_Sales, dtype: Float64\n",
      "\n",
      "    Store  Temperature  Fuel_Price         CPI  Unemployment  Holiday_Flag  \\\n",
      "73      1        85.22       2.619  211.567306         7.787          <NA>   \n",
      "44      1        38.51       2.548   211.24217         8.106             1   \n",
      "78      1        62.25       3.308  218.220509         7.866             0   \n",
      "13      1        64.74       3.734  221.211813         7.348             0   \n",
      "95      1        74.78       2.854  210.337426         7.808             0   \n",
      "\n",
      "    year  month  day  day_of_week  \n",
      "73  2010      8   27            4  \n",
      "44  2010      2   12            4  \n",
      "78  2011     11   18            4  \n",
      "13  2012      3   16            4  \n",
      "95  2010      5   14            4  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Separate target variable Y from features X\n",
    "target_name = 'Weekly_Sales'\n",
    "features_list = ['Store', 'Temperature','Fuel_Price','CPI','Unemployment', 'Holiday_Flag', 'year', 'month', 'day', 'day_of_week']\n",
    "\n",
    "print(\"Separating labels from features...\")\n",
    "Y = df.loc[:,target_name]\n",
    "X = df.loc[:,features_list] # All columns are kept, except the target\n",
    "print(\"...Done.\")\n",
    "print(Y.head())\n",
    "print()\n",
    "print(X.head())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dividing into train and test sets...\n",
      "...Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First : always divide dataset into train set & test set !!\n",
    "\n",
    "\n",
    "print(\"Dividing into train and test sets...\")\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "# test_size indicates the proportion of rows from X and Y that will go into the test dataset while \n",
    "# maintaining the correspondance between the rows from X and Y \n",
    "\n",
    "# random_state is an argument that can be found in all functions that have a pseudo-random behaviour\n",
    "# if random_state is not stated the function will derive a different random result everytime the cell \n",
    "# runs, if random_state is given a value the results will be the same everytime the cell runs while\n",
    "# each different value of radom_state will derive a specific result\n",
    "print(\"...Done.\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *Temperature*, *Fuel_price*, *CPI* and *Unemployment*\n",
    "# Create pipeline for numeric features\n",
    "numeric_features = ['Temperature', 'Fuel_Price', 'CPI', 'Unemployment', 'year', 'month', 'day', 'day_of_week'] # Names of numeric columns in X_train/X_test\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')), # missing values will be replaced by columns' median\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Create pipeline for categorical features\n",
    "categorical_features = ['Store', 'Holiday_Flag'] # Names of categorical columns in X_train/X_test\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')), # missing values will be replaced by most frequent value\n",
    "    ('encoder', OneHotEncoder(drop='first')) # first column will be dropped to avoid creating correlations between features\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ColumnTransformer to make a preprocessor object that describes all the treatments to be done\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing preprocessings on train set...\n",
      "     Store  Temperature  Fuel_Price         CPI  Unemployment  Holiday_Flag  \\\n",
      "17      18        21.33       2.788  131.527903         9.202             0   \n",
      "107      8        33.34       2.548  214.621419         6.299             1   \n",
      "136      4        84.59       3.469    129.1125         5.644          <NA>   \n",
      "45       2        54.63       3.555  220.275944         7.057             0   \n",
      "59      14        36.85       3.695  189.842483         8.424             0   \n",
      "\n",
      "     year  month   day  day_of_week  \n",
      "17   <NA>   <NA>  <NA>         <NA>  \n",
      "107  2010      2    12            4  \n",
      "136  2011      7     8            4  \n",
      "45   2012      2    24            4  \n",
      "59   2012      2    17            4  \n",
      "...Done.\n",
      "[[-2.27582047 -1.16285602 -1.11596452  1.7922351   0.0696733  -0.05386943\n",
      "   0.04276567  0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          1.\n",
      "   0.          0.          0.        ]\n",
      " [-1.59204478 -1.65904467  0.97315281 -1.09692656 -1.18444612 -1.60530895\n",
      "  -0.57305998  0.          0.          0.          0.          0.\n",
      "   0.          0.          1.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          1.        ]\n",
      " [ 1.32581571  0.24507929 -1.17669201 -1.74880423  0.0696733   0.33399045\n",
      "  -1.06572049  0.          0.          0.          1.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.        ]\n",
      " [-0.37992283  0.42288023  1.11531753 -0.34253988  1.32379273 -1.60530895\n",
      "   0.90492157  0.          1.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.        ]\n",
      " [-1.39220692  0.71232361  0.35016673  1.01794376  1.32379273 -1.60530895\n",
      "   0.04276567  0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          1.          0.          0.          0.          0.\n",
      "   0.          0.          0.        ]]\n",
      "\n",
      "Performing preprocessings on test set...\n",
      "    Store  Temperature  Fuel_Price         CPI  Unemployment  Holiday_Flag  \\\n",
      "78      1        62.25       3.308  218.220509         7.866             0   \n",
      "67      3        45.71       2.572  214.424881         7.368             0   \n",
      "72     13        36.78       2.817    126.7934         7.795             0   \n",
      "10      8        82.92       3.554  219.070197         6.425             0   \n",
      "83     15        79.97       3.972  135.873839         7.806             0   \n",
      "\n",
      "    year  month   day  day_of_week  \n",
      "78  2011     11    18            4  \n",
      "67  2010      2     5            4  \n",
      "72  2010     12    10            4  \n",
      "10  2011      8    19            4  \n",
      "83  <NA>   <NA>  <NA>         <NA>  \n",
      "...Done.\n",
      "[[ 0.05391321 -0.0877806   1.06364027  0.46260369  0.0696733   1.88542998\n",
      "   0.1659308   0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.        ]\n",
      " [-0.88777289 -1.60942581  0.9682115  -0.03302239 -1.18444612 -1.60530895\n",
      "  -1.43521588  0.          0.          1.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.        ]\n",
      " [-1.39619229 -1.10289989 -1.23499827  0.39194214 -1.18444612  2.27328986\n",
      "  -0.81939023  0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   1.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.        ]\n",
      " [ 1.23073616  0.42081277  1.08500292 -0.97152719  0.0696733   0.72185033\n",
      "   0.28909593  0.          0.          0.          0.          0.\n",
      "   0.          0.          1.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.        ]\n",
      " [ 1.06278126  1.28500802 -1.00670005  0.40288971  0.0696733  -0.05386943\n",
      "   0.04276567  0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          1.          0.          0.          0.\n",
      "   0.          0.          0.        ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preprocessings on train set\n",
    "print(\"Performing preprocessings on train set...\")\n",
    "print(X_train.head())\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "print('...Done.')\n",
    "print(X_train[0:5]) # MUST use this syntax because X_train is a numpy array and not a pandas DataFrame anymore\n",
    "print()\n",
    "\n",
    "# Preprocessings on test set\n",
    "print(\"Performing preprocessings on test set...\")\n",
    "print(X_test.head()) \n",
    "X_test = preprocessor.transform(X_test) # Don't fit again !! The test set is used for validating decisions\n",
    "# we made based on the training set, therefore we can only apply transformations that were parametered using the training set.\n",
    "# Otherwise this creates what is called a leak from the test set which will introduce a bias in all your results.\n",
    "print('...Done.')\n",
    "print(X_test[0:5,:]) # MUST use this syntax because X_test is a numpy array and not a pandas DataFrame anymore\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-fold cross-validation...\n",
      "The cross-validated R2-score is :  0.8459115572086736\n",
      "The standard deviation is :  0.14322689171326167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nicol\\miniconda3\\envs\\jedha_env\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.116e+11, tolerance: 2.204e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\nicol\\miniconda3\\envs\\jedha_env\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.541e+11, tolerance: 2.068e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\nicol\\miniconda3\\envs\\jedha_env\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.411e+10, tolerance: 1.731e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# Perform 3-fold cross-validation to evaluate the generalized R2 score obtained with a Lasso model\n",
    "print(\"3-fold cross-validation...\")\n",
    "regressor = Lasso()\n",
    "scores = cross_val_score(regressor, X_train, Y_train, cv=3)\n",
    "print('The cross-validated R2-score is : ', scores.mean())\n",
    "print('The standard deviation is : ', scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nicol\\miniconda3\\envs\\jedha_env\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.586e+11, tolerance: 2.598e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\nicol\\miniconda3\\envs\\jedha_env\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.274e+11, tolerance: 2.468e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\nicol\\miniconda3\\envs\\jedha_env\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.863e+11, tolerance: 2.378e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\nicol\\miniconda3\\envs\\jedha_env\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.707e+11, tolerance: 2.352e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\nicol\\miniconda3\\envs\\jedha_env\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.051e+10, tolerance: 2.249e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\nicol\\miniconda3\\envs\\jedha_env\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.518e+11, tolerance: 2.598e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\nicol\\miniconda3\\envs\\jedha_env\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.166e+10, tolerance: 2.468e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\nicol\\miniconda3\\envs\\jedha_env\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.856e+11, tolerance: 2.378e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\nicol\\miniconda3\\envs\\jedha_env\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.696e+11, tolerance: 2.352e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\nicol\\miniconda3\\envs\\jedha_env\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.045e+10, tolerance: 2.249e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\nicol\\miniconda3\\envs\\jedha_env\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.452e+11, tolerance: 2.598e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\nicol\\miniconda3\\envs\\jedha_env\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.953e+10, tolerance: 2.468e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\nicol\\miniconda3\\envs\\jedha_env\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.850e+11, tolerance: 2.378e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\nicol\\miniconda3\\envs\\jedha_env\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.686e+11, tolerance: 2.352e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\nicol\\miniconda3\\envs\\jedha_env\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.039e+10, tolerance: 2.249e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\nicol\\miniconda3\\envs\\jedha_env\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.388e+11, tolerance: 2.598e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\nicol\\miniconda3\\envs\\jedha_env\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.692e+09, tolerance: 2.468e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Done.\n",
      "Best hyperparameters :  {'alpha': 1.0}\n",
      "Best R2 score :  0.9244808027451266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nicol\\miniconda3\\envs\\jedha_env\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.843e+11, tolerance: 2.378e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\nicol\\miniconda3\\envs\\jedha_env\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.675e+11, tolerance: 2.352e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\nicol\\miniconda3\\envs\\jedha_env\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.032e+10, tolerance: 2.249e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\nicol\\miniconda3\\envs\\jedha_env\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.295e+11, tolerance: 2.598e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\nicol\\miniconda3\\envs\\jedha_env\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.834e+11, tolerance: 2.378e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\nicol\\miniconda3\\envs\\jedha_env\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.660e+11, tolerance: 2.352e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\nicol\\miniconda3\\envs\\jedha_env\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.022e+10, tolerance: 2.249e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\nicol\\miniconda3\\envs\\jedha_env\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.174e+11, tolerance: 3.016e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# Perform grid search\n",
    "print(\"Grid search...\")\n",
    "regressor = Lasso()\n",
    "# Grid of values to be tested\n",
    "params = {\n",
    "    'alpha': [0.1, 0.3, 0.5, 0.7, 1.0], # 0 corresponds to no regularization\n",
    "}\n",
    "gridsearch = GridSearchCV(regressor, param_grid = params, cv = 5) # cv : the number of folds to be used for CV\n",
    "gridsearch.fit(X_train, Y_train)\n",
    "print(\"...Done.\")\n",
    "print(\"Best hyperparameters : \", gridsearch.best_params_)\n",
    "print(\"Best R2 score : \", gridsearch.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score on training set :  0.9851311111922835\n",
      "R2 score on test set :  0.947314382948029\n"
     ]
    }
   ],
   "source": [
    "# Print R^2 scores\n",
    "print(\"R2 score on training set : \", gridsearch.score(X_train, Y_train))\n",
    "print(\"R2 score on test set : \", gridsearch.score(X_test, Y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
